{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8c2b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.utils.multiclass import unique_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf60bded",
   "metadata": {},
   "source": [
    "# First Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e81c676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"spam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d03d05e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7d24e5",
   "metadata": {},
   "source": [
    "As we can see there is a lot of null values so we're going to drop them since they are not useful for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29d61ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3bd5a2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98daa58e",
   "metadata": {},
   "source": [
    "We're now going to rename the v1 and v2 columns since the column names do not mean anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2e9c86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns = {\n",
    "    'v1': 'spam',\n",
    "    'v2': 'message'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39f18f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spam                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5982a653",
   "metadata": {},
   "source": [
    "We're now going to change spam values to True, since they do represent spam messages and ham values to false, since they do not represent spam messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eee639b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['spam'].map({'ham': False, 'spam': True})\n",
    "data['spam'] = data['spam'].map({'ham': False, 'spam': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b53e61f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    spam                                            message\n",
       "0  False  Go until jurong point, crazy.. Available only ...\n",
       "1  False                      Ok lar... Joking wif u oni...\n",
       "2   True  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3  False  U dun say so early hor... U c already then say...\n",
       "4  False  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4897743",
   "metadata": {},
   "source": [
    "Just checking the distribution of True and False values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86cdd73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam\n",
       "False    0.865937\n",
       "True     0.134063\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['spam'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3925a68c",
   "metadata": {},
   "source": [
    "For ideal performance our data would have 50% spam and 50% real messages but this is the dataset we have to work with so let's move on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15b21a1",
   "metadata": {},
   "source": [
    "**Splitting the dataset into training and testing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "043f24e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(data['spam'])\n",
    "x = pd.DataFrame(data['message'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['message'], data['spam'], test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8030f64b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam\n",
       "False    0.871214\n",
       "True     0.128786\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b6aaf7",
   "metadata": {},
   "source": [
    "The ratio is very similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b19d58",
   "metadata": {},
   "source": [
    "The message will be split and the count of each word in the message will be tracked with CountVerctorizer inbuilt function. The vectorized count is then converted into an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a7c90b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457, 42941)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range = (1,2)).fit(X_train)\n",
    "X_train_vectorized = vectorizer.transform(X_train)\n",
    "X_train_vectorized.toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aba976f",
   "metadata": {},
   "source": [
    "## The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g. word caounts for text classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "92a6771e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB(alpha=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB(alpha=0.1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB(alpha = 0.1)\n",
    "model.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be9fd63",
   "metadata": {},
   "source": [
    "The alpha value in this case is basically a smoothing parameter. What this means is that we're essentially setting the floor for our initial value for probability guess. Since words like congratulations might only be found in spam messages, we don't want our model to immediately associate that word with a spam message. We want the model to find other factors and build a stronger case as to why it is predicting a spam message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bf1c455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.83408071748879 %\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(vectorizer.transform(X_test))\n",
    "print(\"Accuracy:\", 100 * sum(predictions == y_test) / len(predictions), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a22583c",
   "metadata": {},
   "source": [
    "Accuracy based on the predictions made using the test data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5787b8",
   "metadata": {},
   "source": [
    "**Testing with non-spam messages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "97f10db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(vectorizer.transform(\n",
    "    [\n",
    "        \"Thank you, ABC. Can you also share your LinkedIn profile? As you're a good Python programmer I'd like to see what work environments you've been in and what kind of projects you've worked on so far.\",\n",
    "        \"Hello everybody, we have just opened up a brand new Data Scientist position at ABC Company, if you're interested make sure to head over to the company website and apply now!\",\n",
    "        \"Dear X, Congratulations! You have been selected as a Data Scientist at ABC Company. We are really happy to have you here!\"\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db61b3b6",
   "metadata": {},
   "source": [
    "As we can see all of the predictions on the example messages I wrote are False meaning that the model is working as intended."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ebf31e",
   "metadata": {},
   "source": [
    "**Testing with spam messages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "725bedc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(vectorizer.transform(\n",
    "    [\n",
    "        \"congratulations, you became today's lucky winner\",\n",
    "        \"1-month unlimited calls offer Activate now\",\n",
    "        \"Free money!! click here\"\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826b2e88",
   "metadata": {},
   "source": [
    "The model recognizes these spam messages as spam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a0e545",
   "metadata": {},
   "source": [
    "# Second Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eecba4a",
   "metadata": {},
   "source": [
    "The first method worked great but I wanted to challenge myself a little bit more and not use CountVectorizer. Instead I will be creating my own (probably less efficient) version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "babe4eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam_tf</th>\n",
       "      <th>message_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spam_tf                                      message_input\n",
       "0    False  Go until jurong point, crazy.. Available only ...\n",
       "1    False                      Ok lar... Joking wif u oni...\n",
       "2     True  Free entry in 2 a wkly comp to win FA Cup fina..."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('spam.csv')\n",
    "data.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis = 1, inplace = True)\n",
    "data.rename(columns = {\n",
    "    'v1': 'spam_tf',\n",
    "    'v2': 'message_input'}, inplace = True)\n",
    "data['spam_tf'] = data['spam_tf'].map({'ham': False, 'spam': True})\n",
    "data.dropna(inplace = True)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d986d5",
   "metadata": {},
   "source": [
    "I'll be creating a series of columns where each word is vectorized so I cannot use spam or message as those could be words in the messages I'll be processing. This is why the column names are different for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cee6fcef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>la</th>\n",
       "      <th>aftr</th>\n",
       "      <th>married</th>\n",
       "      <th>msn</th>\n",
       "      <th>via</th>\n",
       "      <th>pie</th>\n",
       "      <th>smokin</th>\n",
       "      <th>letters</th>\n",
       "      <th>gsex</th>\n",
       "      <th>09058091854</th>\n",
       "      <th>...</th>\n",
       "      <th>resume</th>\n",
       "      <th>sender</th>\n",
       "      <th>leading</th>\n",
       "      <th>87121</th>\n",
       "      <th>poboxox36504w45wq</th>\n",
       "      <th>60</th>\n",
       "      <th>logon</th>\n",
       "      <th>09077818151</th>\n",
       "      <th>responding</th>\n",
       "      <th>m39m51</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8670 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   la  aftr  married  msn  via  pie  smokin  letters  gsex  09058091854  ...  \\\n",
       "0   1     0        0    0    0    0       0        0     0            0  ...   \n",
       "1   0     0        0    0    0    0       0        0     0            0  ...   \n",
       "2   0     0        0    0    0    0       0        0     0            0  ...   \n",
       "3   0     0        0    0    0    0       0        0     0            0  ...   \n",
       "4   0     0        0    0    0    0       0        0     0            0  ...   \n",
       "\n",
       "   resume  sender  leading  87121  poboxox36504w45wq  60  logon  09077818151  \\\n",
       "0       0       0        0      0                  0   0      0            0   \n",
       "1       0       0        0      0                  0   0      0            0   \n",
       "2       0       0        0      1                  0   0      0            0   \n",
       "3       0       0        0      0                  0   0      0            0   \n",
       "4       0       0        0      0                  0   0      0            0   \n",
       "\n",
       "   responding  m39m51  \n",
       "0           0       0  \n",
       "1           0       0  \n",
       "2           0       0  \n",
       "3           0       0  \n",
       "4           0       0  \n",
       "\n",
       "[5 rows x 8670 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data cleaning steps taken:\n",
    "# Set it to string dtype\n",
    "data['message_input'] = data['message_input'].astype(str)\n",
    "\n",
    "# Remove punctuation\n",
    "data['message_input'] = data['message_input'].str.replace(r'\\W', ' ', regex=True)\n",
    "\n",
    "# Remove extra spaces\n",
    "data['message_input'] = data['message_input'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "data['message_input'] = data['message_input'].str.lower()\n",
    "#training_set.head(3)\n",
    "\n",
    "# Split on every word\n",
    "data['message_input'] = data['message_input'].str.split()\n",
    "\n",
    "# Embeded loop creates the column names\n",
    "vocabulary = []\n",
    "for sms in data['message_input']:\n",
    "    for word in sms:\n",
    "        vocabulary.append(word)\n",
    "        \n",
    "vocabulary = list(set(vocabulary))\n",
    "\n",
    "word_counts_per_sms = {unique_word: [0] * len(data['message_input'])\n",
    "                      for unique_word in vocabulary}\n",
    "\n",
    "# Fills in the columns with appropriate data\n",
    "for index, sms in enumerate(data['message_input']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1\n",
    "        \n",
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c78ac2",
   "metadata": {},
   "source": [
    "**Concatinating all of the word data and the original data for later use.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d70b3c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam_tf</th>\n",
       "      <th>message_input</th>\n",
       "      <th>la</th>\n",
       "      <th>aftr</th>\n",
       "      <th>married</th>\n",
       "      <th>msn</th>\n",
       "      <th>via</th>\n",
       "      <th>pie</th>\n",
       "      <th>smokin</th>\n",
       "      <th>letters</th>\n",
       "      <th>...</th>\n",
       "      <th>resume</th>\n",
       "      <th>sender</th>\n",
       "      <th>leading</th>\n",
       "      <th>87121</th>\n",
       "      <th>poboxox36504w45wq</th>\n",
       "      <th>60</th>\n",
       "      <th>logon</th>\n",
       "      <th>09077818151</th>\n",
       "      <th>responding</th>\n",
       "      <th>m39m51</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>[nah, i, don, t, think, he, goes, to, usf, he,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8672 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   spam_tf                                      message_input  la  aftr  \\\n",
       "0    False  [go, until, jurong, point, crazy, available, o...   1     0   \n",
       "1    False                     [ok, lar, joking, wif, u, oni]   0     0   \n",
       "2     True  [free, entry, in, 2, a, wkly, comp, to, win, f...   0     0   \n",
       "3    False  [u, dun, say, so, early, hor, u, c, already, t...   0     0   \n",
       "4    False  [nah, i, don, t, think, he, goes, to, usf, he,...   0     0   \n",
       "\n",
       "   married  msn  via  pie  smokin  letters  ...  resume  sender  leading  \\\n",
       "0        0    0    0    0       0        0  ...       0       0        0   \n",
       "1        0    0    0    0       0        0  ...       0       0        0   \n",
       "2        0    0    0    0       0        0  ...       0       0        0   \n",
       "3        0    0    0    0       0        0  ...       0       0        0   \n",
       "4        0    0    0    0       0        0  ...       0       0        0   \n",
       "\n",
       "   87121  poboxox36504w45wq  60  logon  09077818151  responding  m39m51  \n",
       "0      0                  0   0      0            0           0       0  \n",
       "1      0                  0   0      0            0           0       0  \n",
       "2      1                  0   0      0            0           0       0  \n",
       "3      0                  0   0      0            0           0       0  \n",
       "4      0                  0   0      0            0           0       0  \n",
       "\n",
       "[5 rows x 8672 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean = pd.concat([data, word_counts], axis = 1)\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "83bdae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolating spam and ham messages first using masking\n",
    "spam_messages = data_clean[data_clean['spam_tf'] == True]\n",
    "nspam_messages = data_clean[data_clean['spam_tf'] == False]\n",
    "\n",
    "# P(Spam) and P(NSpam)\n",
    "p_spam = len(spam_messages) / len(data_clean)\n",
    "p_nspam = len(nspam_messages) / len(data_clean)\n",
    "\n",
    "# N_Spam\n",
    "n_words_per_spam_message = spam_messages['message_input'].apply(len)\n",
    "n_spam = n_words_per_spam_message.sum()\n",
    "\n",
    "# N_NSpam\n",
    "n_words_per_nspam_message = nspam_messages['message_input'].apply(len)\n",
    "n_nspam = n_words_per_nspam_message.sum()\n",
    "\n",
    "# N_Vocabulary\n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "# Smoothing factor\n",
    "alpha = 1\n",
    "\n",
    "# Initiate parameters\n",
    "parameters_spam = {unique_word: 0 for unique_word in vocabulary}\n",
    "parameters_nspam = {unique_word: 0 for unique_word in vocabulary}\n",
    "\n",
    "# Calculate parameters\n",
    "for word in vocabulary:\n",
    "    n_word_given_spam = spam_messages[word].sum()  # spam_messages already defined\n",
    "    p_word_given_spam = (n_word_given_spam + alpha) / (n_spam + alpha * n_vocabulary)\n",
    "    parameters_spam[word] = p_word_given_spam\n",
    "    \n",
    "    n_word_given_nspam = nspam_messages[word].sum()  # NSpam_messages already defined\n",
    "    p_word_given_nspam = (n_word_given_nspam + alpha) / (n_nspam + alpha * n_vocabulary)\n",
    "    parameters_nspam[word] = p_word_given_nspam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31505bb",
   "metadata": {},
   "source": [
    "Basically what is happening above is I am first creating two different dataframes. One with spam data and one with not spam data. These two dataframes were created using masking. I then calculate the probability of spam messages and not spam messages in the whole dataset. Next, I counted the number of words per spam message and non-spam message separetely to pass a parameter. I then calculated the length of the vocabulary using a len() function and also set the smoothing factor. \n",
    "\n",
    "The for loop at the bottom calculates the parameters that are going to be used. It essentialy takes the number of words given that it is either spam or not spam and calculates its probability. Alpha becomes very important here. it ensures that all of the 0s are not automatically assumed to have a probability of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "821d76d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4825, 8672)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nspam_messages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "617f0782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message_input):\n",
    "    '''\n",
    "    message: a string\n",
    "    '''\n",
    "    \n",
    "    message_input = re.sub('\\W', ' ', message_input)\n",
    "    message_input = message_input.lower().split()\n",
    "    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_nspam_given_message = p_nspam\n",
    "    \n",
    "    for word in message_input:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "            \n",
    "        if word in parameters_nspam:\n",
    "            p_nspam_given_message *= parameters_nspam[word]\n",
    "            \n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(NSpam|message):', p_nspam_given_message)\n",
    "    \n",
    "    if p_nspam_given_message > p_spam_given_message:\n",
    "        print('Label: Not Spam')\n",
    "    elif p_nspam_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print(\"Equal probabilities please have a human classify this\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4a1b86",
   "metadata": {},
   "source": [
    "This function removes all punctuation from the input message, converts it into lower case, and splits every word. This is done to match our training data. It then calculates the probability using precomputed parameters for each word. Then in the for loop, it multiplies the probability with every word in the input message and calculates the probabilities and spits out its classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "914bf3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 2.5910204075339075e-16\n",
      "P(NSpam|message): 2.019112996047724e-17\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify('Click here for your reward!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0fcd0d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 2.217625934299856e-25\n",
      "P(NSpam|message): 6.381611721617781e-28\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify('Winner!! This is the secret code to unlock your money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "372ff2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 2.1813087641172994e-17\n",
      "P(NSpam|message): 6.443853566566209e-14\n",
      "Label: Not Spam\n"
     ]
    }
   ],
   "source": [
    "classify(\"Sounds good, see you there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3fd24292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13406317300789664"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c1e84bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.195059468520307e-07\n",
      "P(NSpam|message): 8.095405440398258e-05\n",
      "Label: Not Spam\n"
     ]
    }
   ],
   "source": [
    "classify(\"I love Ginger.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "836e3df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 9.798729532899553e-28\n",
      "P(NSpam|message): 3.221900580259293e-28\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify(\"Your package was not delivered. Click this link!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0da853e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 5.4857308763844595e-18\n",
      "P(NSpam|message): 4.2521441168058316e-17\n",
      "Label: Not Spam\n"
     ]
    }
   ],
   "source": [
    "classify(\"Your package was not delivered.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891f69d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
